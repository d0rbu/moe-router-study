"""
K-Means Autointerpretability Experiment.

This module implements an autointerpretability system for k-means centroids:
1. Each centroid has a natural-language description with a confidence level
2. Descriptions are cached and lazily generated when needed
3. Explanations are generated by querying top-k validation examples
4. The system can analyze sentences by tokenizing, running through model/k-means,
   and generating explanations for each token
"""

from __future__ import annotations

import asyncio
from dataclasses import asdict, dataclass
from datetime import datetime
import json
from pathlib import Path
from typing import Any

from loguru import logger
from nnterp import StandardizedTransformer
import torch as th
from tqdm import tqdm
from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast

from core.type import assert_type


@dataclass
class CentroidExplanation:
    """Natural language explanation for a k-means centroid."""

    centroid_id: int
    explanation: str
    confidence: float  # 0.0 to 1.0
    top_k_examples: list[str]  # Top activating examples used to generate explanation
    timestamp: str  # ISO format timestamp
    metadata: dict[str, Any]  # Additional info (model, layer, etc.)

    def to_dict(self) -> dict[str, Any]:
        return asdict(self)

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> CentroidExplanation:
        return cls(**data)


class CentroidExplanationCache:
    """Cache for storing and retrieving centroid explanations."""

    def __init__(self, cache_dir: str | Path):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._memory_cache: dict[int, CentroidExplanation] = {}

    def _get_cache_path(self, centroid_id: int) -> Path:
        """Get the file path for a centroid's cached explanation."""
        return self.cache_dir / f"centroid_{centroid_id}.json"

    def get(self, centroid_id: int) -> CentroidExplanation | None:
        """Retrieve explanation for a centroid, returns None if not cached."""
        # Check memory cache first
        if centroid_id in self._memory_cache:
            return self._memory_cache[centroid_id]

        # Check disk cache
        cache_path = self._get_cache_path(centroid_id)
        if cache_path.exists():
            with open(cache_path) as f:
                data = json.load(f)
                explanation = CentroidExplanation.from_dict(data)
                self._memory_cache[centroid_id] = explanation
                return explanation

        return None

    def set(self, explanation: CentroidExplanation) -> None:
        """Store an explanation in the cache."""
        # Store in memory
        self._memory_cache[explanation.centroid_id] = explanation

        # Store on disk
        cache_path = self._get_cache_path(explanation.centroid_id)
        with open(cache_path, "w") as f:
            json.dump(explanation.to_dict(), f, indent=2)

    def has(self, centroid_id: int) -> bool:
        """Check if an explanation exists for a centroid."""
        if centroid_id in self._memory_cache:
            return True
        return self._get_cache_path(centroid_id).exists()

    def clear(self) -> None:
        """Clear all cached explanations."""
        self._memory_cache.clear()
        for cache_file in self.cache_dir.glob("centroid_*.json"):
            cache_file.unlink()


@dataclass
class ValidationExample:
    """A single validation example with its activation value."""

    text: str
    tokens: list[int]
    token_strings: list[str]
    activation: float
    token_position: int  # Which token in the sequence had this activation


class KMeansAutoInterp:
    """
    Autointerpretability system for k-means centroids.

    This class handles:
    - Caching of centroid explanations
    - Querying top-k validation examples for a centroid
    - Generating natural language explanations via LLM
    - Analyzing sentences to produce token-level explanations
    """

    def __init__(
        self,
        cache_dir: str | Path,
        model: StandardizedTransformer,
        centroids: th.Tensor,  # (num_centroids, hidden_dim)
        validation_activations: th.Tensor | None = None,  # (num_samples, seq_len, hidden_dim)
        validation_tokens: th.Tensor | None = None,  # (num_samples, seq_len)
        layer_idx: int | None = None,
        activation_type: str = "layer_output",
    ):
        """
        Initialize the K-Means AutoInterp system.

        Args:
            cache_dir: Directory to store cached explanations
            model: The transformer model
            centroids: K-means centroids tensor
            validation_activations: Pre-computed validation activations (optional)
            validation_tokens: Validation dataset tokens (optional)
            layer_idx: Which layer the centroids correspond to
            activation_type: Type of activation (layer_output, mlp_output, etc.)
        """
        self.cache = CentroidExplanationCache(cache_dir)
        self.model = model
        self.centroids = centroids
        self.validation_activations = validation_activations
        self.validation_tokens = validation_tokens
        self.layer_idx = layer_idx
        self.activation_type = activation_type
        self.num_centroids = centroids.shape[0]
        self.hidden_dim = centroids.shape[1]

        logger.info(
            f"Initialized KMeansAutoInterp with {self.num_centroids} centroids, "
            f"hidden_dim={self.hidden_dim}, layer={layer_idx}"
        )

    def get_top_k_validation_examples(
        self,
        centroid_id: int,
        k: int = 10,
        validation_activations: th.Tensor | None = None,
        validation_tokens: th.Tensor | None = None,
    ) -> list[ValidationExample]:
        """
        Get the top-k validation examples that activate a centroid most strongly.

        Args:
            centroid_id: ID of the centroid to analyze
            k: Number of top examples to return
            validation_activations: Optional override for validation activations
            validation_tokens: Optional override for validation tokens

        Returns:
            List of ValidationExample objects sorted by activation strength
        """
        if validation_activations is None:
            validation_activations = self.validation_activations
        if validation_tokens is None:
            validation_tokens = self.validation_tokens

        if validation_activations is None or validation_tokens is None:
            raise ValueError(
                "Validation activations and tokens must be provided either during "
                "initialization or as arguments"
            )

        # Get the centroid vector
        centroid = self.centroids[centroid_id]  # (hidden_dim,)

        # Compute distances from all activations to this centroid
        # validation_activations: (num_samples, seq_len, hidden_dim)
        # distances: (num_samples, seq_len)
        distances = th.cdist(
            validation_activations.view(-1, self.hidden_dim).unsqueeze(0),
            centroid.unsqueeze(0).unsqueeze(0),
        ).squeeze()

        # Get indices of top-k smallest distances (closest matches)
        flat_indices = th.topk(-distances, k=min(k, distances.numel())).indices

        # Convert flat indices back to (sample_idx, token_idx)
        _num_samples, seq_len = validation_tokens.shape
        sample_indices = flat_indices // seq_len
        token_indices = flat_indices % seq_len

        # Build ValidationExample objects
        examples = []
        tokenizer = assert_type(
            self.model.tokenizer, PreTrainedTokenizer | PreTrainedTokenizerFast
        )

        for i in range(len(flat_indices)):
            sample_idx = sample_indices[i].item()
            token_idx = token_indices[i].item()

            tokens = validation_tokens[sample_idx].tolist()
            token_strings = tokenizer.convert_ids_to_tokens(tokens)
            text = tokenizer.decode(tokens, skip_special_tokens=False)

            activation = -distances[flat_indices[i]].item()  # Convert back to positive

            examples.append(
                ValidationExample(
                    text=text,
                    tokens=tokens,
                    token_strings=token_strings,
                    activation=activation,
                    token_position=token_idx,
                )
            )

        return examples

    async def generate_explanation(
        self,
        centroid_id: int,
        examples: list[ValidationExample],
        llm_client: Any | None = None,
    ) -> CentroidExplanation:
        """
        Generate a natural language explanation for a centroid using an LLM.

        Args:
            centroid_id: ID of the centroid
            examples: Top validation examples
            llm_client: LLM client for generating explanations (e.g., OpenAI, Anthropic)

        Returns:
            CentroidExplanation with the generated explanation and confidence
        """
        # Format examples for the prompt
        example_texts = []
        for i, ex in enumerate(examples[:10]):  # Use top 10 examples
            # Highlight the activated token
            highlighted_tokens = ex.token_strings.copy()
            activated_token = highlighted_tokens[ex.token_position]
            highlighted_tokens[ex.token_position] = f"**{activated_token}**"
            highlighted_text = "".join(highlighted_tokens)

            example_texts.append(
                f"Example {i+1} (activation={ex.activation:.3f}):\n{highlighted_text}"
            )

# TODO: Implement LLM-based explanation generation using the examples above

        # If no LLM client provided, return a simple heuristic explanation
        if llm_client is None:
            # Simple heuristic: look at most common tokens
            token_counts: dict[str, int] = {}
            for ex in examples:
                token = ex.token_strings[ex.token_position]
                token_counts[token] = token_counts.get(token, 0) + 1

            most_common = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)
            top_tokens = [tok for tok, _ in most_common[:3]]

            explanation = (
                f"Feature activates on tokens: {', '.join(top_tokens)}. "
                f"Appears in {len(examples)} validation examples."
            )
            confidence = 0.5  # Low confidence for heuristic

            return CentroidExplanation(
                centroid_id=centroid_id,
                explanation=explanation,
                confidence=confidence,
                top_k_examples=[ex.text for ex in examples[:5]],
                timestamp=datetime.now().isoformat(),
                metadata={
                    "layer_idx": self.layer_idx,
                    "activation_type": self.activation_type,
                    "generation_method": "heuristic",
                },
            )

        # TODO: Implement actual LLM call here
        # This would use the provided llm_client to call an API
        # For now, returning heuristic explanation
        logger.warning("LLM client not fully implemented, using heuristic explanation")

        explanation = (
            f"Feature {centroid_id} activates on specific patterns in layer {self.layer_idx}"
        )
        confidence = 0.5

        return CentroidExplanation(
            centroid_id=centroid_id,
            explanation=explanation,
            confidence=confidence,
            top_k_examples=[ex.text for ex in examples[:5]],
            timestamp=datetime.now().isoformat(),
            metadata={
                "layer_idx": self.layer_idx,
                "activation_type": self.activation_type,
                "generation_method": "llm",
            },
        )

    async def get_or_generate_explanation(
        self,
        centroid_id: int,
        k: int = 10,
        llm_client: Any | None = None,
        force_regenerate: bool = False,
    ) -> CentroidExplanation:
        """
        Get explanation for a centroid, generating it if not cached.

        Args:
            centroid_id: ID of the centroid
            k: Number of validation examples to use
            llm_client: LLM client for generating explanations
            force_regenerate: Force regeneration even if cached

        Returns:
            CentroidExplanation for the centroid
        """
        # Check cache first
        if not force_regenerate:
            cached = self.cache.get(centroid_id)
            if cached is not None:
                logger.debug(f"Using cached explanation for centroid {centroid_id}")
                return cached

        # Generate new explanation
        logger.info(f"Generating explanation for centroid {centroid_id}")

        examples = self.get_top_k_validation_examples(centroid_id, k=k)
        explanation = await self.generate_explanation(centroid_id, examples, llm_client)

        # Cache it
        self.cache.set(explanation)

        return explanation

    def assign_tokens_to_centroids(
        self,
        activations: th.Tensor,  # (seq_len, hidden_dim)
    ) -> th.Tensor:
        """
        Assign each token's activation to the nearest centroid.

        Args:
            activations: Token activations (seq_len, hidden_dim)

        Returns:
            Tensor of centroid IDs (seq_len,)
        """
        # Compute distances to all centroids
        # activations: (seq_len, hidden_dim)
        # centroids: (num_centroids, hidden_dim)
        # distances: (seq_len, num_centroids)
        distances = th.cdist(activations, self.centroids)

        # Get nearest centroid for each token
        centroid_ids = th.argmin(distances, dim=1)

        return centroid_ids

    async def analyze_sentence(
        self,
        sentence: str,
        k: int = 10,
        llm_client: Any | None = None,
    ) -> list[dict[str, Any]]:
        """
        Analyze a sentence and return explanations for each token.

        Args:
            sentence: Input sentence to analyze
            k: Number of validation examples to use for explanation generation
            llm_client: LLM client for generating explanations

        Returns:
            List of dicts containing token info and explanations
        """
        # Tokenize the sentence
        tokenizer = assert_type(
            self.model.tokenizer, PreTrainedTokenizer | PreTrainedTokenizerFast
        )
        encoded = tokenizer(sentence, return_tensors="pt")
        tokens = encoded["input_ids"].squeeze(0)  # (seq_len,)

        # Run through model to get activations
        with self.model.trace(tokens.unsqueeze(0)):
            # Extract activations based on type
            if self.activation_type == "layer_output":
                if self.layer_idx is not None:
                    activations = self.model.layers_output[self.layer_idx].save()
                else:
                    raise ValueError("layer_idx must be specified for layer_output")
            elif self.activation_type == "mlp_output":
                if self.layer_idx is not None:
                    activations = self.model.mlps_output[self.layer_idx].save()
                else:
                    raise ValueError("layer_idx must be specified for mlp_output")
            elif self.activation_type == "attn_output":
                if self.layer_idx is not None:
                    activations = self.model.attentions_output[self.layer_idx].save()
                else:
                    raise ValueError("layer_idx must be specified for attn_output")
            else:
                raise ValueError(f"Unsupported activation_type: {self.activation_type}")

        # activations: (1, seq_len, hidden_dim)
        activations = activations.squeeze(0)  # (seq_len, hidden_dim)

        # Assign each token to nearest centroid
        centroid_ids = self.assign_tokens_to_centroids(activations)

        # Get or generate explanations for each unique centroid
        unique_centroids = centroid_ids.unique().tolist()
        explanations_map = {}

        for centroid_id in tqdm(unique_centroids, desc="Generating explanations"):
            explanation = await self.get_or_generate_explanation(
                centroid_id, k=k, llm_client=llm_client
            )
            explanations_map[centroid_id] = explanation

        # Build result for each token
        results = []
        token_strings = tokenizer.convert_ids_to_tokens(tokens.tolist())

        for i, (token, token_str, centroid_id) in enumerate(
            zip(tokens.tolist(), token_strings, centroid_ids.tolist(), strict=False)
        ):
            explanation = explanations_map[centroid_id]
            results.append(
                {
                    "position": i,
                    "token_id": token,
                    "token_str": token_str,
                    "centroid_id": centroid_id,
                    "explanation": explanation.explanation,
                    "confidence": explanation.confidence,
                    "activation_magnitude": activations[i].norm().item(),
                }
            )

        return results

    async def interpret_with_meta_model(
        self,
        sentence: str,
        k: int = 10,
        llm_client: Any | None = None,
    ) -> str:
        """
        Analyze a sentence and use a meta-model to interpret how the model works.

        This implements step 3 of the autointerpretability pipeline:
        Feed tokens and natural language explanations into a final model
        that interprets how the model works.

        Args:
            sentence: Input sentence to analyze
            k: Number of validation examples to use
            llm_client: LLM client for generating explanations

        Returns:
            Natural language interpretation of how the model processes this sentence
        """
        # Get token-level explanations
        token_analyses = await self.analyze_sentence(sentence, k=k, llm_client=llm_client)

        # Format the analysis for the meta-model
        analysis_text = f"Sentence: {sentence}\n\nToken-by-token analysis:\n"

        for analysis in token_analyses:
            analysis_text += (
                f"\nToken {analysis['position']}: '{analysis['token_str']}'\n"
                f"  Centroid: {analysis['centroid_id']}\n"
                f"  Explanation: {analysis['explanation']}\n"
                f"  Confidence: {analysis['confidence']:.2f}\n"
                f"  Activation: {analysis['activation_magnitude']:.3f}\n"
            )

        # Create prompt for meta-interpretation
        meta_prompt = f"""You are analyzing how a neural network processes text. Below is a detailed token-by-token analysis showing which features activate for each token.

{analysis_text}

Based on this analysis, provide a high-level interpretation of how the model is processing this sentence. Explain:
1. What patterns or features the model is detecting
2. How different parts of the sentence activate different features
3. What this reveals about the model's internal representations

Provide a clear, concise interpretation (2-3 paragraphs).
"""

        # If no LLM client, provide a simple summary
        if llm_client is None:
            # Count centroid usage
            centroid_counts: dict[int, int] = {}
            for analysis in token_analyses:
                cid = analysis["centroid_id"]
                centroid_counts[cid] = centroid_counts.get(cid, 0) + 1

            summary = (
                f"The model processes the sentence '{sentence}' using {len(centroid_counts)} "
                f"distinct features (centroids). "
            )

            if len(centroid_counts) > 1:
                most_used = max(centroid_counts.items(), key=lambda x: x[1])
                summary += (
                    f"Feature {most_used[0]} is most prominent, activating on {most_used[1]} tokens. "
                )

            avg_confidence = sum(a["confidence"] for a in token_analyses) / len(
                token_analyses
            )
            summary += (
                f"\nAverage explanation confidence: {avg_confidence:.2f}\n\n"
                f"For detailed explanations of each feature, an LLM client is recommended."
            )

            return summary

        # TODO: Implement actual meta-model LLM call
        logger.warning("Meta-model LLM not fully implemented, using simple summary")
        return meta_prompt


# Utility functions for loading k-means results

def load_kmeans_centroids(
    kmeans_path: str | Path,
) -> tuple[th.Tensor, dict[str, Any]]:
    """
    Load k-means centroids from a saved file.

    Args:
        kmeans_path: Path to the saved k-means centroids

    Returns:
        Tuple of (centroids tensor, metadata dict)
    """
    checkpoint = th.load(kmeans_path)

    if isinstance(checkpoint, dict):
        centroids = checkpoint.get("centroids")
        metadata = checkpoint.get("metadata", {})
    else:
        # Assume it's just the centroids tensor
        centroids = checkpoint
        metadata = {}

    return centroids, metadata


async def run_sentence_analysis_example(
    sentence: str,
    cache_dir: str | Path,
    model_name: str = "gpt2",
    centroids_path: str | Path | None = None,
    layer_idx: int = 6,
):
    """
    Example function demonstrating the full pipeline.

    Args:
        sentence: Sentence to analyze
        cache_dir: Directory for caching explanations
        model_name: Name of the model to use
        centroids_path: Path to saved k-means centroids
        layer_idx: Which layer to analyze
    """

    # Load model
    logger.info(f"Loading model: {model_name}")
    model = StandardizedTransformer(
        model_name,
        device_map="auto",
    )

    # Load or create dummy centroids
    if centroids_path is not None:
        logger.info(f"Loading centroids from {centroids_path}")
        centroids, _metadata = load_kmeans_centroids(centroids_path)
    else:
        logger.warning("No centroids provided, creating dummy centroids for demo")
        # Create dummy centroids for demonstration
        hidden_dim = model.config.hidden_size
        num_centroids = 100
        centroids = th.randn(num_centroids, hidden_dim)
# metadata = {"num_centroids": num_centroids, "hidden_dim": hidden_dim}  # unused for now

    # Initialize autointerp system
    logger.info("Initializing KMeansAutoInterp")
    autointerp = KMeansAutoInterp(
        cache_dir=cache_dir,
        model=model,
        centroids=centroids,
        layer_idx=layer_idx,
        activation_type="layer_output",
    )

    # Analyze the sentence
    logger.info(f"Analyzing sentence: {sentence}")
    results = await autointerp.analyze_sentence(sentence, k=10)

    # Print results
    print("\n" + "=" * 80)
    print(f"ANALYSIS RESULTS FOR: {sentence}")
    print("=" * 80)

    for result in results:
        print(
            f"\nToken {result['position']}: '{result['token_str']}' "
            f"(centroid {result['centroid_id']})"
        )
        print(f"  Explanation: {result['explanation']}")
        print(f"  Confidence: {result['confidence']:.2f}")
        print(f"  Activation: {result['activation_magnitude']:.3f}")

    # Get meta-interpretation
    print("\n" + "=" * 80)
    print("META-INTERPRETATION")
    print("=" * 80)

    interpretation = await autointerp.interpret_with_meta_model(sentence, k=10)
    print(interpretation)


if __name__ == "__main__":
    # Example usage
    asyncio.run(
        run_sentence_analysis_example(
            sentence="The quick brown fox jumps over the lazy dog.",
            cache_dir="artifacts/kmeans_autointerp_cache",
            model_name="gpt2",
            layer_idx=6,
        )
    )
