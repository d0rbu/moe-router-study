++ scontrol show hostnames g073
++ head -n 1
+ export MASTER_ADDR=g073
+ MASTER_ADDR=g073
+++ echo -n 16736257
+++ tail -c 4
++ expr 10000 + 6257
+ export MASTER_PORT=16257
+ MASTER_PORT=16257
+ export RANK=0
+ RANK=0
+ export WORLD_SIZE=1
+ WORLD_SIZE=1
+ cd /scratch/user/henrycastillo/moe-router-study
+ srun --ntasks=1 --ntasks-per-node=1 uv run exp/sae.py main --log-level TRACE --num-workers 16 --trainers-per-gpu 2 --expansion-factor 16,32,64 --k 160,320,640 --layer 6,7,8,9 --tokens-per-file 100000 --reshuffled-tokens-per-file 100000
warning: The `extra-build-dependencies` option is experimental and may change without warning. Pass `--preview-features extra-build-dependencies` to disable this warning.
2025-10-06 18:33:55.201 | WARNING  | nnterp.utils:<module>:67 - nnterp was not tested with Transformers version 4.56.0.dev0. Closest below: 4.53.2, closest above: None
This is most likely okay, but you may want to at least check that the attention probabilities hook makes sense by calling `model.attention_probabilities.print_source()`. It is recommended to switch to 4.53.2 if possible or:
  - run the nnterp tests with your version of transformers to ensure everything works as expected using `python -m nnterp run_tests` to update the status file locally.
  - check if the attention probabilities hook makes sense before using them by calling `model.attention_probabilities.print_source()` (prettier in a notebook).
Using test status from 4.53.2.
2025-10-06 18:33:55.202 | WARNING  | nnterp.utils:<module>:118 - nnterp was not tested with NNsight version 0.5.0.dev13 for transformers version 4.56.0.dev0. Closest below: 0.5.0.dev9, closest above: None
This is most likely okay, but you may want to at least check that the attention probabilities hook makes sense by calling `model.attention_probabilities.print_source()`. It is recommended to switch to NNsight 0.5.0.dev9 if possible.
Otherwise, consider:
  - run the nnterp tests with your version of transformers to ensure everything works as expected using `python -m nnterp run_tests` to update the status file locally.
  - check if the attention probabilities hook makes sense before using them by calling `model.attention_probabilities.print_source()` (prettier in a notebook).
Using test results from NNsight 0.5.0.dev9.
2025-10-06 18:34:25.396 | DEBUG    | __main__:main:562 - Running with log level: TRACE
2025-10-06 18:34:25.396 | DEBUG    | __main__:run_sae_training:198 - loading activations and initializing distributed setup
2025-10-06 18:34:25.396 | TRACE    | __main__:run_sae_training:199 - model_name=olmoe-i
dataset_name=lmsys
expansion_factor=(16, 32, 64)
k=(160, 320, 640)
layer=(6, 7, 8, 9)
group_fractions=((0.03125, 0.0625, 0.125, 0.25, 0.53125),)
group_weights=(None,)
architecture=('batchtopk',)
lr=(5e-05,)
auxk_alpha=(0.03125,)
warmup_steps=()
decay_start=(None,)
threshold_beta=(0.999,)
threshold_start_step=(1024,)
k_anneal_steps=(None,)
seed=(0,)
submodule_name=('mlp_output',)
batch_size=128
trainers_per_gpu=2
steps=1024
save_every=1024
num_epochs=1
context_length=2048
tokens_per_file=100000
reshuffled_tokens_per_file=100000
num_workers=16
debug=True
dtype=torch.bfloat16

2025-10-06 18:34:25.396 | DEBUG    | exp.activations:load_activations_and_init_dist:704 - Loading from experiment olmoe-i_lmsys_context_length=2048_tokens_per_file=100000
2025-10-06 18:34:25.396 | DEBUG    | exp.activations:load_activations_and_init_dist:710 - Initializing distributed process group
2025-10-06 18:34:26.120 | INFO     | exp.activations:load_activations_and_init_dist:713 - Rank 0 initialized gloo group
2025-10-06 18:34:26.346 | INFO     | exp.activations:load_activations_and_init_dist:722 - Rank 0 initialized nccl group
2025-10-06 18:34:26.346 | DEBUG    | exp.activations:load_activations_and_init_dist:728 - Initializing activations with seed 0
2025-10-06 18:34:26.346 | TRACE    | exp.activations:load:92 - Loading or reshuffling activations from out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations
2025-10-06 18:34:26.498 | TRACE    | exp.activations:get_activation_filepaths:343 - Found 9 activation files
2025-10-06 18:34:26.498 | TRACE    | exp.activations:get_activation_filepaths:349 - Found 9 activation indices
2025-10-06 18:34:26.498 | TRACE    | exp.activations:get_activation_filepaths:360 - Max contiguous activation index: 8
2025-10-06 18:34:26.498 | TRACE    | exp.activations:load_files:311 - Found shuffled activation files ['out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/0.pt', 'out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/1.pt', 'out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/2.pt', 'out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/3.pt', 'out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/4.pt', 'out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/5.pt', 'out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/6.pt', 'out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/7.pt', 'out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/8.pt']
2025-10-06 18:34:26.498 | DEBUG    | exp.activations:load_activations_and_init_dist:740 - Activation filepaths count: 9
2025-10-06 18:34:26.498 | DEBUG    | exp.activations:load_activations_and_init_dist:742 - First filepath: out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/0.pt
2025-10-06 18:34:30.935 | DEBUG    | exp.activations:load_activations_and_init_dist:748 - Sample data keys: ['topk', 'layers', 'router_layers', 'layer_output', 'mlp_output', 'router_logits']
2025-10-06 18:34:30.935 | DEBUG    | exp.activations:load_activations_and_init_dist:750 - MLP output shape: torch.Size([100000, 4, 2048])
2025-10-06 18:34:32.154 | DEBUG    | exp.activations:_get_file_data:133 - Loaded file out/olmoe-i_lmsys_context_length=2048_tokens_per_file=100000/activations/reshuffled-seed=0-tokens_per_file=100000/0.pt
2025-10-06 18:34:32.154 | DEBUG    | exp.activations:_get_file_data:134 - File data keys: dict_keys(['topk', 'layers', 'router_layers', 'layer_output', 'mlp_output', 'router_logits'])
2025-10-06 18:34:33.819 | DEBUG    | exp.activations:__call__:166 - Loaded data with shape torch.Size([100000, 4, 2048])
2025-10-06 18:34:34.401 | TRACE    | exp.activations:load_activations_and_init_dist:771 - Activation: layer_output: torch.Size([1, 4, 2048]), mlp_output: torch.Size([1, 4, 2048]), router_logits: torch.Size([1, 16, 64])
2025-10-06 18:34:34.666 | DEBUG    | exp.activations:load_activations_and_init_dist:784 - Activation dims: {'mlp_output': 2048}
2025-10-06 18:34:34.666 | DEBUG    | exp.activations:__call__:278 - GeneratorExit received, stopping activations worker process
2025-10-06 18:34:34.666 | TRACE    | exp.activations:__call__:280 - Activations worker process terminated
2025-10-06 18:34:34.666 | TRACE    | exp.activations:__call__:282 - Cached file data queue closed
2025-10-06 18:34:35.059 | INFO     | __main__:run_sae_training:296 - Number of GPUs: 2
2025-10-06 18:34:35.059 | DEBUG    | __main__:run_sae_training:337 - Parameters before product():
2025-10-06 18:34:35.059 | DEBUG    | __main__:run_sae_training:339 -   expansion_factor: (16, 32, 64) (len: 3)
2025-10-06 18:34:35.059 | DEBUG    | __main__:run_sae_training:339 -   k: (160, 320, 640) (len: 3)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   layer: (6, 7, 8, 9) (len: 4)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   group_fractions: ((0.03125, 0.0625, 0.125, 0.25, 0.53125),) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   group_weights: (None,) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   architecture: ('batchtopk',) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   lr: (5e-05,) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   auxk_alpha: (0.03125,) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   warmup_steps: () (len: 0)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   decay_start: (None,) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   threshold_beta: (0.999,) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   threshold_start_step: (1024,) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   k_anneal_steps: (None,) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   seed: (0,) (len: 1)
2025-10-06 18:34:35.060 | DEBUG    | __main__:run_sae_training:339 -   submodule_name: ('mlp_output',) (len: 1)
2025-10-06 18:34:35.060 | ERROR    | __main__:run_sae_training:384 - Hparam sweep iterator is empty:
expansion_factor=(16, 32, 64)
k=(160, 320, 640)
layer=(6, 7, 8, 9)
group_fractions=((0.03125, 0.0625, 0.125, 0.25, 0.53125),)
group_weights=(None,)
architecture=('batchtopk',)
lr=(5e-05,)
auxk_alpha=(0.03125,)
warmup_steps=()
decay_start=(None,)
threshold_beta=(0.999,)
threshold_start_step=(1024,)
k_anneal_steps=(None,)
seed=(0,)
submodule_name=('mlp_output',)
2025-10-06 18:34:35.060 | INFO     | __main__:gpu_worker:130 - [worker 0]: Starting GPU worker
2025-10-06 18:34:35.060 | DEBUG    | __main__:gpu_worker:134 - [worker 0]: Awaiting batch 0
2025-10-06 18:34:35.060 | INFO     | __main__:gpu_worker:130 - [worker 1]: Starting GPU worker
2025-10-06 18:34:35.060 | DEBUG    | __main__:gpu_worker:134 - [worker 1]: Awaiting batch 0
Exception in callback handle_exceptions(<Task cancell...p/sae.py:118>>) at /scratch/user/henrycastillo/moe-router-study/core/async_utils.py:7
handle: <Handle handle_exceptions(<Task cancell...p/sae.py:118>>) at /scratch/user/henrycastillo/moe-router-study/core/async_utils.py:7>
Traceback (most recent call last):
  File "/home/henrycastillo/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/asyncio/events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "/scratch/user/henrycastillo/moe-router-study/core/async_utils.py", line 14, in handle_exceptions
    exception = task.exception()
                ^^^^^^^^^^^^^^^^
  File "/scratch/user/henrycastillo/moe-router-study/exp/sae.py", line 135, in gpu_worker
    _priority, _trainer_batch_idx, batch = await gpu_queue.get()
                                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/henrycastillo/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/asyncio/queues.py", line 158, in get
    await getter
asyncio.exceptions.CancelledError
Exception in callback handle_exceptions(<Task cancell...p/sae.py:118>>) at /scratch/user/henrycastillo/moe-router-study/core/async_utils.py:7
handle: <Handle handle_exceptions(<Task cancell...p/sae.py:118>>) at /scratch/user/henrycastillo/moe-router-study/core/async_utils.py:7>
Traceback (most recent call last):
  File "/home/henrycastillo/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/asyncio/events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "/scratch/user/henrycastillo/moe-router-study/core/async_utils.py", line 14, in handle_exceptions
    exception = task.exception()
                ^^^^^^^^^^^^^^^^
  File "/scratch/user/henrycastillo/moe-router-study/exp/sae.py", line 135, in gpu_worker
    _priority, _trainer_batch_idx, batch = await gpu_queue.get()
                                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/henrycastillo/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/asyncio/queues.py", line 158, in get
    await getter
asyncio.exceptions.CancelledError
[rank0]:[W1006 18:34:35.620343734 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
